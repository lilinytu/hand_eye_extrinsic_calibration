
import json
import open3d
import numpy as np
from transforms3d.euler import euler2mat, mat2euler
from transforms3d.quaternions import quat2mat
from copy import deepcopy
import cv2
import apriltag
from scipy.optimize import minimize, least_squares
from scipy.linalg import orthogonal_procrustes

import scripts_source_functions as src

inv = np.linalg.inv

KINECT_COLOR_HEIGHT = 540
KINECT_COLOR_WIDTH = 960

board_2_tip = np.eye(4)
# board_2_tip[:3,-1] = [-0.05,0.07,0.06]

#read tip && ee
json_file = "world_frame_to_ee_tip_0_tfs.json"
with open(json_file, 'r') as f:
    wf_2_eetip = json.load(f)

wf_2_cam_gt_data = {
    "position": [
      1.6729682311702465, 
      0.08451025077097321, 
      2.014965414389718
    ], 
    "orientation": [
      0.05256023904098993, 
      -0.7142395129244176, 
      -0.69346038049903, 
      0.07881649654472865
    ]
}


wf_2_cam_gt = np.eye(4)
wf_2_cam_gt[:3,:3] = quat2mat(wf_2_cam_gt_data["orientation"])
wf_2_cam_gt[:3,-1] = wf_2_cam_gt_data["position"]

board_2_camera_transforms = {
    "0": np.array([
         [ 0.0021196 ,  0.98966514, -0.14338205, 0.14301349],
         [-0.99822499, -0.00643985, -0.05920642, 0.08151079],
         [-0.05951789,  0.14325304,  0.98789483, -0.75303407],
         [ 0.        ,  0.        ,  0.        , 1.        ],
        ]),
    "1": np.array([
        [ 0.00491762,  0.98752156, -0.15740709, -0.01292298],
        [-0.99762778, -0.00596347, -0.06858018,  0.09177108],
        [-0.0686631 ,  0.15737094,  0.98514962, -0.75139905],
        [ 0.        ,  0.        ,  0.        ,  1.        ],]
        ),
    "2": np.array([
        [-0.00107013,  0.98708561, -0.16019005,  0.00812102],
        [-0.90787891, -0.06811573, -0.41366185,  0.05758388],
        [-0.41923112,  0.1449905 ,  0.8962271 , -0.7795221 ],
        [ 0.        ,  0.        ,  0.        ,  1.        ],]
        ),
    "3" : np.array(
        [[ 0.01996435,  0.99006736, -0.13916913, 0.03654961],
        [-0.95571742 , 0.05977575 , 0.28815111 ,-0.06125018],
        [ 0.29360795 , 0.12725361 , 0.94741801 ,-0.67052147],
        [ 0.         , 0.         , 0.         , 1.        ],]
        ),
    "4" : np.array(
        [[-0.05346486,  0.98808148,  0.1443485,  -0.08816442],
        [-0.99687512 ,-0.04439549 ,-0.06533787,  0.16814429],
        [-0.05815072 ,-0.1473907  , 0.98736745, -0.80065168],
        [ 0.         , 0.         , 0.        ,  1.        ],]
) 
}

def get_transformations(file_id):
    """cam_2_board"""
    board_2_cam = board_2_camera_transforms[file_id]
    cam_2_board = inv(board_2_cam)

    """wf_2_tip"""
    transform_data = wf_2_eetip["world_frame_to_ee_tip_0_tfs"][file_id]
    td = transform_data
    quat = np.array([td["w_rot"], td["x_rot"], td["y_rot"], td["z_rot"]], dtype=np.float32)
    t = np.array([td["x_pos"], td["y_pos"], td["z_pos"]], dtype=np.float32)
    R = quat2mat(quat)
    wf_2_tip = np.eye(4)
    wf_2_tip[:3,:3] = R
    wf_2_tip[:3,-1] = t
    tip_2_wf = inv(wf_2_tip)

    """ approximate board_2_tip""" 
    global board_2_tip
    #,-0.1]
    # board_2_tip[:3,:3] = euler2mat(3.14, 0, 0)  # rotate x-axis by 180

    return cam_2_board, board_2_tip, tip_2_wf


# def coor_trans(file_id):
# # file_id = "2"
#     pcd_file = "cloud_xyzrgba/cloud_xyzrgba_%s.pcd"%(file_id)
#     cloud = open3d.read_point_cloud(pcd_file)

#     cam_2_board, board_2_tip, tip_2_wf = get_transformations(file_id)
#     wf_2_tip = inv(tip_2_wf)

#     # cam_2_wf_wo_bt = np.dot(cam_2_board, tip_2_wf)

#     mesh_frame_cal = open3d.create_mesh_coordinate_frame(size = 0.1, origin = [0,0,0])
#     # mesh_frame_cal.transform(cam_2_board)


#     cam_2_tip = np.dot(cam_2_board, board_2_tip)
#     cam_2_wf = np.dot(cam_2_tip, tip_2_wf)
#     mesh_frame_cal.transform(cam_2_tip)


#     cam_2_tip_gt = np.dot(inv(wf_2_cam_gt), wf_2_tip) 
#     mesh_frame_app = open3d.create_mesh_coordinate_frame(size = 0.3, origin = [0,0,0])
#     mesh_frame_app.transform(cam_2_tip_gt)
#     # mesh_frame_app.transform(cam_2_wf)
#     # mesh_frame_gt = open3d.create_mesh_coordinate_frame(size = 0.5, origin = [0,0,0])
#     # mesh_frame_gt.transform(inv(wf_2_cam_gt))

#     open3d.draw_geometries([cloud, mesh_frame_cal, mesh_frame_app])

def extractImgNPoints(cloud):
    points = np.asarray(cloud.points)
    color = np.asarray(cloud.colors)
    img = color.reshape((KINECT_COLOR_HEIGHT, KINECT_COLOR_WIDTH, 3)) * 255
    img = img.astype(np.uint8)
    img = img[:,:,::-1]
    return img, points

# Used to produce filtered point cloud, only they are possible to display in open3d
# cloud -> source cloud; new_cloud -> filtered cloud
def RemoveNanData(cloud, new_cloud):
    nan_idx = np.isnan(cloud.points)
    wo_nan_idx = np.all(nan_idx == False, axis=1)

    points = np.asarray(cloud.points)

    new_points = points[wo_nan_idx]
    
    new_cloud.points = open3d.Vector3dVector(new_points)

    has_color = cloud.has_colors()
    if(has_color):
        colors = np.asarray(cloud.colors)
        new_colors = colors[wo_nan_idx]
        new_cloud.colors = open3d.Vector3dVector(new_colors)


def detectTagCorner(cloud, img, points_3d, cloud_name):
    detector = apriltag.Detector()
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    detections, dimg = detector.detect(gray, True)  

    if len(img.shape) == 3:
        overlay = img // 2 + dimg[:, :, None] // 2
    else:
        overlay = gray // 2 + dimg // 2

    for detection in detections:
        # print("current tag {} in image".format(detection.tag_id))
        opoints = []
        points = np.round(detection.corners).astype(int)
        try:
            for point in points:
                x, y = point
                cv2.circle(overlay, (x, y), 4, (0,0,255), -1)
                if np.any(np.isnan(points_3d[x+y*KINECT_COLOR_WIDTH])):
                    raise ValueError
                opoints.append(points_3d[x+y*KINECT_COLOR_WIDTH])

        except ValueError:
            print("Corner point in image is not registered by camera. It has 'nan' value, Please change the view")
        
        # cv2.imshow('Window: '+cloud_name, overlay) 
        # while cv2.waitKey(5) < 0:
        #     pass    

    return np.asarray(opoints)

# # Iterative optimizer from current implementation of calibration program ## Didn't got good results for our problem
# def opti(Th):
#     # Initialization
#     M = len(board_2_camera_transforms)
#     M = 2
#     Kinect2Marker = np.zeros((4,4,M))
#     Base2End = Kinect2Marker.copy()
#     # error = np.zeros((M,1))
#     R_Kinect2Marker = np.zeros((3,3,M))
#     t_Kinect2Marker = np.zeros((3,M))
#     R_Base2End = np.zeros((3,3,M))
#     t_Base2End = np.zeros((3,M))

#     for i in range(M):
#         cam_2_board, board_2_tip, tip_2_wf = get_transformations(str(i))
#         R_Kinect2Marker[:,:,i] = cam_2_board[0:3,0:3]
#         t_Kinect2Marker[:,i] = cam_2_board[0:3,3]

#         wf_2_tip = inv(tip_2_wf)
#         R_Base2End[:,:,i] = wf_2_tip[0:3,0:3]
#         t_Base2End[:,i] = wf_2_tip[0:3,3]

#     cam_2_board, board_2_tip, tip_2_wf = get_transformations("0")
#     cam_2_wf= np.dot(np.dot(cam_2_board, board_2_tip), tip_2_wf)
#     wf_2_cam = inv(cam_2_wf)
#     tip_2_board = inv(board_2_tip)
#     print("initial trans", wf_2_cam)

#     R_BK_init,t_BK_init,t_EM_init = src.initial(R_Base2End,t_Base2End,t_Kinect2Marker)
#     print(t_EM_init)
#     print("initial rot:",mat2euler(R_BK_init))
#     # print(R_BK_init)
#     # print(wf_2_cam[:3,:3])
#     # wf_2_cam = np.eye(4)    
#     # R_BK_init = wf_2_cam[:3,:3]
#     # t_BK_init = wf_2_cam[:3,3][:,None]
#     # t_EM_init = tip_2_board[:3,3][:,None]

#     R_BK,t_BK,t_EM = src.iterative(R_BK_init,t_Kinect2Marker,t_BK_init,R_Base2End,t_EM_init,t_Base2End,Th)
#     print("our transf", cam_2_wf)
#     print("cal transf:", R_BK_init, "\ntranslation:", t_BK_init.shape )
#     return t_EM, R_BK, t_BK


def updateTrans(trans):
    global board_2_tip
    board_2_tip[:3,-1] = trans

def updateRot(trans):
    global board_2_tip
    board_2_tip[:3,:3] = trans

def getRotFrReg(pt1, pt2, mark_p1, mark_p2, color1, color2):
    mark1_max = np.max(mark_p1)
    mark1_min = np.min(mark_p1)
    mark2_max = np.max(mark_p2)
    mark2_min = np.min(mark_p2)

    c1 = open3d.PointCloud()
    c2 = open3d.PointCloud()

    #ignore the warning #Anyway we don't want points with 'nan' value
    pt1_ls_id  = pt1 < mark1_max
    pt1_gt_id = pt1 > mark1_min
    pt1_qual = np.logical_and(pt1_gt_id, pt1_ls_id)
    points1_idx = np.all(pt1_qual == True, axis=1)
    c1.points = open3d.Vector3dVector(pt1[points1_idx])
    c1.colors = open3d.Vector3dVector(color1[points1_idx])

    pt2_ls_id  = pt2 < mark2_max
    pt2_gt_id = pt2 > mark2_min
    pt2_qual = np.logical_and(pt2_gt_id, pt2_ls_id)
    points2_idx = np.all(pt2_qual == True, axis=1)
    c2.points = open3d.Vector3dVector(pt2[points2_idx])
    c2.colors = open3d.Vector3dVector(color2[points2_idx])

    threshold = 0.01
    t_init = np.eye(4)
    reg = open3d.registration_icp(c2, c1, threshold, t_init, open3d.TransformationEstimationPointToPoint(), open3d.ICPConvergenceCriteria(max_iteration = 50))
    # c2.transform(reg.transformation)
    # open3d.draw_geometries([c1, c2])

    return reg.transformation[:3,:3], reg.transformation[:3,3]

def opt_trans(trans, dim, file_1, file_2):
    global board_2_tip
    if dim == "rot":
        rot = euler2mat(trans[0], trans[1], trans[2])
        board_2_tip[:3,:3] = rot
    else:
        board_2_tip[:3,-1] = trans

    pcd_file = "cloud_xyzrgba/cloud_xyzrgba_%s.pcd"%(file_1)
    cloud_1 = open3d.read_point_cloud_with_nan(pcd_file)

    pcd_file = "cloud_xyzrgba/cloud_xyzrgba_%s.pcd"%(file_2)
    cloud_2 = open3d.read_point_cloud_with_nan(pcd_file)

    cam_2_board_1, board_2_tip_1, tip_2_wf_1 = get_transformations(file_1)
    cam_2_tip_1 = np.dot(cam_2_board_1, board_2_tip_1)
    cam_2_wf_1 = np.dot(cam_2_tip_1, tip_2_wf_1)

    cam_2_board_2, board_2_tip_2, tip_2_wf_2 = get_transformations(file_2)
    cam_2_tip_2 = np.dot(cam_2_board_2, board_2_tip_2)
    cam_2_wf_2 = np.dot(cam_2_tip_2, tip_2_wf_2)
    # b_sc1_2_sc2 = np.dot( cam_2_board_2, inv(cam_2_board_1))
 
    #for experimenting with the clouds just transforming one cloud and will compare to the original (ground truth)
    c1 = deepcopy(cloud_1)
    c2 = deepcopy(cloud_1)
    c2.transform(np.dot(cam_2_wf_1, inv(cam_2_wf_2)))

    img1, pt1 = extractImgNPoints(c1)
    img2, pt2 = extractImgNPoints(c2)

    p1_3d = detectTagCorner(c1, img1, pt1, "one")
    p2_3d = detectTagCorner(c2, img2, pt2, "two")

    # diff = p1_3d - p2_3d

    # if dim == 'x':
    #     # print("x")
    #     return sumSq(diff.T[0])
    # elif dim == 'y':
    #     # print('y')
    #     return sumSq(diff.T[1])
    # elif dim == 'z':
    #     return sumSq(diff.T[2]) 
    # elif dim == "rot_x":
    #     euler_angle = np.asarray(mat2euler(rot))
    #     return euler_angle[0]
    if dim == "rot":
        # rot, scale = orthogonal_procrustes(p1_3d, p2_3d)
        # euler_angle = np.asarray(mat2euler(rot))
        rot_icp, trans_icp = getRotFrReg(pt1, pt2, p1_3d,p2_3d, np.asarray(c1.colors), np.asarray(c2.colors))
        euler_angle = np.asarray(mat2euler(rot_icp))
        return sumSq(euler_angle)
    elif dim == 'd':
        diff = np.sum(p1_3d - p2_3d, axis=0)/len(p1_3d)
        return sumSq(diff)  
        # return sumSq(trans_icp)


def sumSq(arr):
    return sum(arr**2)


if __name__ == "__main__":
    
    # init_t = np.array([-0.05,0.07,0.06])
    # init_t = np.array([-0.05,0.07,0.01])
    # init_t = np.array([0.0, 0.1, -0.1])
    init_t = np.array([0.0, 0.0, 0.0])
    updateTrans(init_t)
    x = np.deg2rad(210)
    y = np.deg2rad(-30)
    z = np.deg2rad(-30)
    # x, y, z = -2.9689421059634786, 0.04259118727932657, 1.548878411706393
    init_r = np.array([x, y, z])
    # init_r = np.array([0.0, 0, 0])
    updateRot(euler2mat(init_r[0], init_r[1], init_r[2]))

    file_list = ["3","4","0"]
    # file_list = ["3","4","0","1","2" ]
    iteration = len(file_list)

    for i in range(len(file_list)):
        # break
        f1_id = i
        f2_id = (i+1)%len(file_list)
        file_1 = file_list[f1_id]
        file_2 = file_list[f2_id]

        res1  = minimize(opt_trans, init_t, args = ('d', file_1, file_2), method="SLSQP", options={'disp':True})
        updateTrans(res1.x)
        print("updated trans", res1.x)
        init_t = res1.x

        res1  = minimize(opt_trans, init_r, args = ("rot", file_1, file_2), method="SLSQP", options={'disp':True})
        print("first update rot", res1.x)
        updateRot(euler2mat(res1.x[0],res1.x[1],res1.x[2]))
        init_r = np.array([res1.x[0],res1.x[1],res1.x[2]])

        res1  = minimize(opt_trans, init_t, args = ('d', file_1, file_2), method="SLSQP", options={'disp':True})
        updateTrans(res1.x)
        print("updated trans", res1.x)
        init_t = res1.x

        res1  = minimize(opt_trans, init_r, args = ("rot", file_1, file_2), method="SLSQP", options={'disp':True})
        print("first update rot", res1.x)
        updateRot(euler2mat(res1.x[0],res1.x[1],res1.x[2]))
        init_r = np.array([res1.x[0],res1.x[1],res1.x[2]])
        # # break #just run it once

    """iter opti"""
    # tip_2_board_t, wf_2_cam_r, wf_2_cam_t = opti(1e-04)
    # new_wf_2_cam = np.eye(4)
    # new_wf_2_cam[:3,:3] = wf_2_cam_r
    # new_wf_2_cam[:3,3] = wf_2_cam_t[:,0]
    # print("\nnew result", new_wf_2_cam)

    print("\n gt wf", wf_2_cam_gt)

    # det = opt_trans(init, 'd') #no use for now
    file_1 = file_list[0] # visualizing results on first 2 scenes, better match -> better results
    file_2 = file_list[1]

    pcd_file = "cloud_xyzrgba/cloud_xyzrgba_%s.pcd"%(file_1)
    cloud_1 = open3d.read_point_cloud_with_nan(pcd_file)

    pcd_file = "cloud_xyzrgba/cloud_xyzrgba_%s.pcd"%(file_2)
    cloud_2 = open3d.read_point_cloud_with_nan(pcd_file)

    cam_2_board_1, board_2_tip_1, tip_2_wf_1 = get_transformations(file_1)
    cam_2_tip_1 = np.dot(cam_2_board_1, board_2_tip_1)
    cam_2_wf_1 = np.dot(cam_2_tip_1, tip_2_wf_1)

    cam_2_board_2, board_2_tip_2, tip_2_wf_2 = get_transformations(file_2)
    cam_2_tip_2 = np.dot(cam_2_board_2, board_2_tip_2)
    cam_2_wf_2 = np.dot(cam_2_tip_2, tip_2_wf_2)
    # b_sc1_2_sc2 = np.dot( cam_2_board_2, inv(cam_2_board_1))
    
    #more close the two axis frame -> more accurate calc
    mesh_frame_gt = open3d.create_mesh_coordinate_frame(size = 0.5, origin = [0,0,0]) #original camera frame
    wf_2_baord_gt = np.dot(inv(wf_2_cam_gt), inv(tip_2_wf_2))
    mesh_frame_gt.transform(inv(wf_2_cam_gt))
    # mesh_frame_gt.transform(inv(cam_2_wf_2))
    """iter opti"""
    # mesh_frame = open3d.create_mesh_coordinate_frame(size = 0.3, origin = [0,0,0]) # tip frame (using gt)
    # wf_2_baord_c = np.dot(inv(new_wf_2_cam), inv(tip_2_wf_1))
    # mesh_frame.transform(wf_2_baord_c)

    mesh_frame1 = open3d.create_mesh_coordinate_frame(size = 0.8, origin = [0,0,0]) # tip frame (using gt)
    # wf_2_baord1 = np.dot((cam_2_wf_1), inv(tip_2_wf_2))
    mesh_frame1.transform(cam_2_wf_1)

    #for displaying the results 
    c1_filter = open3d.PointCloud()
    c2_filter = open3d.PointCloud()
    RemoveNanData(cloud_1, c1_filter)
    RemoveNanData(cloud_2, c2_filter)
    c1 = deepcopy(c1_filter)
    # c1_filter.transform(np.dot(wf_2_cam_gt, inv(wf_2_cam_gt)))
    # c1.transform(cam_2_wf_1)

    print("cal result:", cam_2_wf_1)
    """Experimenting with transformations """

    c1_filter.transform(np.dot(cam_2_wf_1, inv(cam_2_wf_2))) #to obs distortion due to inaccuracy
    # c1_filter.transform(cam_2_wf_2)
    # c1_filter.transform(inv(wf_2_cam_gt))
    open3d.draw_geometries([ c1, c1_filter, mesh_frame_gt, mesh_frame1])
    # open3d.draw_geometries([ c1, c1_filter])